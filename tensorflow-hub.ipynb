{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据并分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'作词：徐若瑄\\n\\n作曲：周杰伦\\n\\n编曲：周杰伦\\n\\n想要有直升机 想要和妳飞到宇宙去\\n\\n想要和妳融化在一起 融化在银河里\\n\\n我每天每天每天在想想想想着妳\\n\\n这样的甜蜜 让我开始相信命运\\n\\n感谢地心引力 让我碰到妳\\n\\n漂亮的让我面红的可爱女人\\n\\n温柔的让我心疼的可爱女人\\n\\n透明的让我感动的可爱女人\\n\\n坏坏的让我疯狂的可爱女人\\n\\n漂亮的让我面红的可爱女人\\n\\n温柔的让我心疼的可爱女人\\n\\n透明的让我感动的可爱女人\\n\\n坏坏的让我疯狂的可爱女人\\n\\n(间奏)\\n\\n让我面红的 让我面红的\\n\\n让我心疼的 让我心疼的\\n\\n让我感动的 让我感动的\\n\\n让我疯狂的 让我疯狂的\\n\\n让我面红的 让我面红的\\n\\n让我心疼的 让我心疼的\\n\\n让我感动的 让我感动的\\n\\n让我疯狂的 让我疯狂的\\n\\n想要有直升机 想要和妳飞到宇宙去(想要和妳)\\n\\n想要和妳融化在一起(想要和妳) 融化在银河里\\n\\n我每天每天每天在想想想想着妳(我 想想想想着妳)\\n\\n这样的甜蜜 让我开始相信命运(让我开始)\\n\\n感谢地心引力 让我碰到妳(感谢地心引力 让我碰到你~)\\n\\n漂亮的让我面红的可爱女人\\n\\n温柔的让我心疼的可爱女人\\n\\n透明的让我感动的可爱女人\\n\\n坏坏的让我疯狂的可爱女人\\n\\n漂亮的让我面红的可爱女人\\n\\n温柔的让我心疼的可爱女人\\n\\n透明的让我感动的可爱女人\\n\\n坏坏的让我疯狂的可爱女人\\n\\n世界这样大而我而我只是只小小小的蚂蚁(小小小)\\n\\n但我要尽全力全力全力保护妳\\n\\n漂亮的让我面红的可爱女人\\n\\n温柔的让我心疼的可爱女人\\n\\n透明的让我感动的可爱女人\\n\\n坏坏的让我疯狂的可爱女人\\n\\n漂亮的让我面红的可爱女人\\n\\n温柔的让我心疼的可爱女人\\n\\n透明的让我感动的可爱女人\\n\\n坏坏的让我疯狂的可爱女人(WOW~呜~ 女人 让我面红的 心~疼的女人)\\n\\n漂亮的让我面红的可爱女人\\n\\n温柔的让我心疼的可爱女人\\n\\n透明的让我感动的可爱女人\\n\\n坏坏的让我疯狂的可爱女人\\n\\n漂亮的让我面红的可爱女人\\n\\n温柔的让我心疼的可爱女人\\n\\n透明的让我感动的'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = pd.read_csv('all_songs_info.csv', index_col='song')\n",
    "lyric = songs.loc['可爱女人', 'lyric']\n",
    "lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['作词 ： 徐若瑄 作曲 ： 周杰伦 编曲 ： 周杰伦 想要 有 直升机 想要 和 妳 飞到 宇宙 去 想要 和 妳 融化 在 一起 融化 在 银河 里 我 每天 每天 每天 在 想想 想想 着 妳 这样 的 甜蜜 让 我 开始 相信 命运 感谢 地心引力 让 我 碰到 妳 漂亮 的 让 我 面红 的 可爱 女人 温柔 的 让 我 心疼 的 可爱 女人 透明 的 让 我 感动 的 可爱 女人 坏坏 的 让 我 疯狂 的 可爱 女人 漂亮 的 让 我 面红 的 可爱 女人 温柔 的 让 我 心疼 的 可爱 女人 透明 的 让 我 感动 的 可爱 女人 坏坏 的 让 我 疯狂 的 可爱 女人 ( 间奏 ) 让 我 面红 的 让 我 面红 的 让 我 心疼 的 让 我 心疼 的 让 我 感动 的 让 我 感动 的 让 我 疯狂 的 让 我 疯狂 的 让 我 面红 的 让 我 面红 的 让 我 心疼 的 让 我 心疼 的 让 我 感动 的 让 我 感动 的 让 我 疯狂 的 让 我 疯狂 的 想要 有 直升机 想要 和 妳 飞到 宇宙 去 ( 想要 和 妳 ) 想要 和 妳 融化 在 一起 ( 想要 和 妳 ) 融化 在 银河 里 我 每天 每天 每天 在 想想 想想 着 妳 ( 我 想想 想想 着 妳 ) 这样 的 甜蜜 让 我 开始 相信 命运 ( 让 我 开始 ) 感谢 地心引力 让 我 碰到 妳 ( 感谢 地心引力 让 我 碰到 你 ~ ) 漂亮 的 让 我 面红 的 可爱 女人 温柔 的 让 我 心疼 的 可爱 女人 透明 的 让 我 感动 的 可爱 女人 坏坏 的 让 我 疯狂 的 可爱 女人 漂亮 的 让 我 面红 的 可爱 女人 温柔 的 让 我 心疼 的 可爱 女人 透明 的 让 我 感动 的 可爱 女人 坏坏 的 让 我 疯狂 的 可爱 女人 世界 这样 大而 我 而 我 只是 只 小 小小的 蚂蚁 ( 小小 小 ) 但 我 要 尽全力 全力 全力 保护 妳 漂亮 的 让 我 面红 的 可爱 女人 温柔 的 让 我 心疼 的 可爱 女人 透明 的 让 我 感动 的 可爱 女人 坏坏 的 让 我 疯狂 的 可爱 女人 漂亮 的 让 我 面红 的 可爱 女人 温柔 的 让 我 心疼 的 可爱 女人 透明 的 让 我 感动 的 可爱 女人 坏坏 的 让 我 疯狂 的 可爱 女人 ( WOW ~ 呜 ~ 女人 让 我 面红 的 心 ~ 疼 的 女人 ) 漂亮 的 让 我 面红 的 可爱 女人 温柔 的 让 我 心疼 的 可爱 女人 透明 的 让 我 感动 的 可爱 女人 坏坏 的 让 我 疯狂 的 可爱 女人 漂亮 的 让 我 面红 的 可爱 女人 温柔 的 让 我 心疼 的 可爱 女人 透明 的 让 我 感动 的']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = jieba.cut(lyric)\n",
    "words = [word for word in words if word not in ['\\n', '\\t', ' ']]\n",
    "words = [' '.join(words)]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载需要用到的词嵌入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module_2/embeddings/part_0:0 from checkpoint b'C:\\\\Users\\\\secsi\\\\AppData\\\\Local\\\\Temp\\\\tfhub_modules\\\\cf1aacb6a0cba69335bfe822a2c3d714925efbfb\\\\variables\\\\variables' with embeddings\n"
     ]
    }
   ],
   "source": [
    "embed = hub.Module('https://tfhub.dev/google/nnlm-zh-dim128/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_hub.module.Module"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\secsi\\.virtualenvs\\anayzing-jay-chou-songs-eu7t5y6x\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.tables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embed 的输入中，列表中的每一项都是分好词的结果（一个句子），用空格分开，最终得到的 embeddings 就是输入该句子对应的词向量。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
